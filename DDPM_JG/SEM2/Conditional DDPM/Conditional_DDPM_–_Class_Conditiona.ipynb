{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \\\n",
        "    diffusers==0.30.3 \\\n",
        "    accelerate==1.1.1 \\\n",
        "    torchmetrics[image]==1.4.0.post0 \\\n",
        "    torchvision==0.19.1 \\\n",
        "    torch-fidelity==0.3.0 \\\n",
        "    lpips==0.1.4 \\\n",
        "    tqdm \\\n",
        "    pillow\n",
        "!pip -q install einops scipy\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "QlIhsJ1Xoy1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENV + IMPORTS + GLOBAL CONFIG"
      ],
      "metadata": {
        "id": "6Sdc71dfpt_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import re, copy, csv, pathlib, random, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "from torchvision import transforms, utils as tvu\n",
        "import torchvision.transforms.functional as tvf\n",
        "\n",
        "from diffusers import UNNet2DModel, DDPMScheduler\n",
        "from accelerate import Accelerator\n",
        "\n",
        "from torchmetrics.functional import (\n",
        "    structural_similarity_index_measure as ssim_fn,\n",
        "    peak_signal_noise_ratio as psnr_fn,\n",
        "    mean_squared_error as mse_fn\n",
        ")\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "import lpips\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- params ----------------\n",
        "IMG       = 128\n",
        "BATCH     = 8          # physical batch size\n",
        "GRAD_ACC  = 2          # effective batch ~ 16\n",
        "EPOCHS    = 200\n",
        "LR        = 1e-5\n",
        "T_STEPS   = 1000\n",
        "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "CFG_SCALE = 2.0\n",
        "\n",
        "# HU windowing (lungs)\n",
        "WL        = -600.0\n",
        "WW        = 1500.0\n",
        "\n",
        "# labels from masks\n",
        "MIN_NODULE_PX = 10\n",
        "NODULE_VAL    = 255\n",
        "\n",
        "# how often to compute heavy metrics\n",
        "EVAL_EVERY = 10\n",
        "\n",
        "# --------------- regex ------------------\n",
        "_re_lung_np   = re.compile(r\"^(.*)_lung_mask_(\\d+)\\.npy$\")\n",
        "_re_comb_np   = re.compile(r\"^(.*)_combined_mask_(\\d+)\\.npy$\")\n",
        "_re_nod_np    = re.compile(r\"^(.*)_nodule_mask_(\\d+)\\.npy$\")\n",
        "_re_slice_npy = re.compile(r\"^(.*)_slice_(\\d+)\\.npy$\")"
      ],
      "metadata": {
        "id": "UEzEDZvRo7ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HELPERS"
      ],
      "metadata": {
        "id": "Bfrn0BUOp9qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _load_npy(p: pathlib.Path) -> np.ndarray:\n",
        "    a = np.load(p)\n",
        "    return a[len(a)//2] if a.ndim == 3 else a\n",
        "\n",
        "def read_patient_list(path: pathlib.Path):\n",
        "    if not path.exists():\n",
        "        return set()\n",
        "    with open(path, \"r\") as f:\n",
        "        return set(line.strip().split(\"_\")[0] for line in f if line.strip())\n",
        "\n",
        "def _patient_from_prefix(prefix: str) -> str:\n",
        "    return prefix.split(\"_\")[0]\n",
        "\n",
        "def window_hu_01(img_hu: np.ndarray, wl=WL, ww=WW) -> np.ndarray:\n",
        "    lo, hi = wl - ww / 2.0, wl + ww / 2.0\n",
        "    img = np.clip(img_hu, lo, hi)\n",
        "    return (img - lo) / (hi - lo + 1e-6)"
      ],
      "metadata": {
        "id": "n2KeDBEXp1YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "r2o3DglsqEMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LungSlice(Dataset):\n",
        "    \"\"\"\n",
        "    NPY-only. Returns:\n",
        "        lung_mask (1,H,W), ct (1,H,W), class_map (1,H,W), label (0/1).\n",
        "    \"\"\"\n",
        "    def __init__(self, root, img_size=IMG, split=None, forced_patients=None):\n",
        "        root = pathlib.Path(root)\n",
        "        self.root, self.img_size = root, img_size\n",
        "\n",
        "        if forced_patients is not None and len(forced_patients) > 0:\n",
        "            split_set = forced_patients\n",
        "        elif split in {\"train\", \"val\", \"test\"}:\n",
        "            split_set = read_patient_list(root / f\"{split}_patients.txt\")\n",
        "        else:\n",
        "            split_set = None  # use all\n",
        "\n",
        "        lung_np, nod_np, comb_np, ct_npy = {}, {}, {}, {}\n",
        "        for p in root.rglob(\"*.npy\"):\n",
        "            n = p.name\n",
        "            if   (m := _re_lung_np.match(n)):   lung_np[(m[1], m[2])] = p\n",
        "            elif (m := _re_nod_np.match(n)):    nod_np[(m[1], m[2])]  = p\n",
        "            elif (m := _re_comb_np.match(n)):   comb_np[(m[1], m[2])] = p\n",
        "            elif (m := _re_slice_npy.match(n)): ct_npy[(m[1], m[2])]  = p\n",
        "\n",
        "        self.trip = []\n",
        "        keys = set(lung_np.keys()) | set(ct_npy.keys()) | set(nod_np.keys()) | set(comb_np.keys())\n",
        "        for k in keys:\n",
        "            prefix, idx = k\n",
        "            if split_set is not None and _patient_from_prefix(prefix) not in split_set:\n",
        "                continue\n",
        "\n",
        "            lung_p = lung_np.get(k)\n",
        "            if lung_p is None:\n",
        "                continue\n",
        "\n",
        "            ct_p = ct_npy.get(k)\n",
        "            if ct_p is None:\n",
        "                cand = root / f\"{prefix}_slice_{idx}.npy\"\n",
        "                ct_p = cand if cand.exists() else None\n",
        "            if ct_p is None:\n",
        "                continue\n",
        "\n",
        "            nm_p  = nod_np.get(k)\n",
        "            cmb_p = comb_np.get(k)\n",
        "            self.trip.append((lung_p, nm_p, cmb_p, ct_p, prefix, idx))\n",
        "\n",
        "        if not self.trip:\n",
        "            raise RuntimeError(\"No (CT slice, lung_mask[, nodule/combined]) pairs found.\")\n",
        "\n",
        "        random.shuffle(self.trip)\n",
        "\n",
        "        self.mask_tf = transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size), antialias=True, interpolation=Image.NEAREST),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t > 0.5).float())\n",
        "        ])\n",
        "\n",
        "        self.labels, self._precheck = [], []\n",
        "        for lung_p, nod_p, cmb_p, ct_p, prefix, idx in self.trip:\n",
        "            if nod_p is not None:\n",
        "                a = _load_npy(nod_p)\n",
        "                y = int((a > 0).sum() >= MIN_NODULE_PX)\n",
        "                src = \"nodule_mask\"\n",
        "            elif cmb_p is not None:\n",
        "                a = _load_npy(cmb_p)\n",
        "                y = int((a == NODULE_VAL).sum() >= MIN_NODULE_PX)\n",
        "                src = \"combined_mask\"\n",
        "            else:\n",
        "                y = 0\n",
        "                src = \"none\"\n",
        "            self.labels.append(y)\n",
        "            self._precheck.append((f\"{prefix}_slice_{idx}\", y, src))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trip)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        lung_p, _, _, ct_p, prefix, idx = self.trip[i]\n",
        "\n",
        "        lung = _load_npy(lung_p)\n",
        "        lung = ((lung > 0).astype(np.uint8) * 255)\n",
        "        m_lung = self.mask_tf(Image.fromarray(lung))  # (1,H,W)\n",
        "\n",
        "        ct = _load_npy(ct_p).astype(np.float32)\n",
        "        lo, hi = WL - WW / 2.0, WL + WW / 2.0\n",
        "        ct = np.clip(ct, lo, hi)\n",
        "        ct = (ct - lo) / (hi - lo + 1e-6)\n",
        "        ct = torch.from_numpy(ct).unsqueeze(0)\n",
        "        ct = F.interpolate(ct.unsqueeze(0), size=(self.img_size, self.img_size),\n",
        "                           mode=\"bilinear\", align_corners=False).squeeze(0)\n",
        "        ct = ct * 2 - 1\n",
        "\n",
        "        y = int(self.labels[i])\n",
        "        class_map = torch.full_like(m_lung, float(y))\n",
        "\n",
        "        return m_lung, ct, class_map, y\n"
      ],
      "metadata": {
        "id": "H7yaeEaCqCMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BALANCED BATCH SAMPLER"
      ],
      "metadata": {
        "id": "5ci-zRtCqKtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BalancedBatchSampler(Sampler):\n",
        "    def __init__(self, labels, batch_size):\n",
        "        assert batch_size % 2 == 0, \"BATCH must be even\"\n",
        "        self.batch_size = batch_size\n",
        "        self.pos = [i for i, y in enumerate(labels) if y == 1]\n",
        "        self.neg = [i for i, y in enumerate(labels) if y == 0]\n",
        "        if len(self.pos) == 0 or len(self.neg) == 0:\n",
        "            raise RuntimeError(\"Both classes are required.\")\n",
        "        random.shuffle(self.pos)\n",
        "        random.shuffle(self.neg)\n",
        "        self.len_batches = min(len(self.pos), len(self.neg)) * 2 // self.batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        pos_ptr, neg_ptr = 0, 0\n",
        "        for _ in range(self.len_batches):\n",
        "            batch = []\n",
        "            for _ in range(self.batch_size // 2):\n",
        "                if pos_ptr >= len(self.pos):\n",
        "                    random.shuffle(self.pos)\n",
        "                    pos_ptr = 0\n",
        "                batch.append(self.pos[pos_ptr])\n",
        "                pos_ptr += 1\n",
        "            for _ in range(self.batch_size // 2):\n",
        "                if neg_ptr >= len(self.neg):\n",
        "                    random.shuffle(self.neg)\n",
        "                    neg_ptr = 0\n",
        "                batch.append(self.neg[neg_ptr])\n",
        "                neg_ptr += 1\n",
        "            random.shuffle(batch)\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_batches"
      ],
      "metadata": {
        "id": "cqOZK8rwqN4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL + SCHEDULER"
      ],
      "metadata": {
        "id": "8J-S2Y1sqRWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(img_size=IMG, t_steps=T_STEPS):\n",
        "    unet = UNet2DModel(\n",
        "        sample_size        = img_size,\n",
        "        in_channels        = 3,   # [lung_mask, class_map, x_t]\n",
        "        out_channels       = 1,\n",
        "        block_out_channels = (32, 64, 96),\n",
        "        down_block_types   = (\"DownBlock2D\",) * 3,\n",
        "        up_block_types     = (\"UpBlock2D\",) * 3,\n",
        "        layers_per_block   = 1,\n",
        "    )\n",
        "    sched = DDPMScheduler(num_train_timesteps=t_steps)\n",
        "    return unet, sched\n"
      ],
      "metadata": {
        "id": "b_aE5NG0qTWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EMA"
      ],
      "metadata": {
        "id": "hqGqPjV7qWK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        self.register(model)\n",
        "\n",
        "    def register(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[name] = p.detach().clone()\n",
        "\n",
        "    def update(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[name].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "\n",
        "    def copy_to(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                p.data.copy_(self.shadow[name].data)\n"
      ],
      "metadata": {
        "id": "igxs_7-nqVmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAMPLING GRID"
      ],
      "metadata": {
        "id": "daGGstcaqZk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_grid(unet, base_sched, dataset, fn, steps=50, img_size=IMG, device=DEVICE):\n",
        "    unet.eval()\n",
        "    test_indices = list(range(min(len(dataset), 128)))\n",
        "\n",
        "    pos, neg = [], []\n",
        "    for idx in test_indices:\n",
        "        ml, ct, cls, y = dataset[idx]\n",
        "        (pos if y == 1 else neg).append((idx, ml, ct, cls, y))\n",
        "    random.seed(0)\n",
        "    random.shuffle(pos)\n",
        "    random.shuffle(neg)\n",
        "    cases = (pos[:2] if len(pos) >= 2 else pos) + (neg[:2] if len(neg) >= 2 else neg)\n",
        "    if len(cases) == 0:\n",
        "        return\n",
        "\n",
        "    lung = torch.stack([c[1] for c in cases]).to(device)\n",
        "    ctgt = torch.stack([c[2] for c in cases])\n",
        "    cls  = torch.stack([c[3] for c in cases]).to(device)\n",
        "\n",
        "    scheduler = copy.deepcopy(base_sched)\n",
        "    scheduler.set_timesteps(steps, device=device)\n",
        "\n",
        "    x = torch.randn((len(cases), 1, img_size, img_size), device=device)\n",
        "    for t in scheduler.timesteps:\n",
        "        inp_c = torch.cat([lung, cls, x], 1)\n",
        "        inp_u = torch.cat([lung, torch.zeros_like(cls), x], 1)\n",
        "        eps_c = unet(inp_c, t).sample\n",
        "        eps_u = unet(inp_u, t).sample\n",
        "        eps   = eps_u + CFG_SCALE * (eps_c - eps_u)\n",
        "        x     = scheduler.step(eps, t, x).prev_sample\n",
        "    gen = x.clamp(-1, 1).cpu()\n",
        "\n",
        "    rows = []\n",
        "    for y, g in zip(ctgt, gen):\n",
        "        rows.extend([y.repeat(3, 1, 1), g.repeat(3, 1, 1)])\n",
        "    grid = tvu.make_grid(rows, nrow=2, normalize=True, value_range=(-1, 1))\n",
        "    tvf.to_pil_image(grid).save(fn)\n",
        "\n",
        "\n",
        "# %% FIXED TEST SUBSET\n",
        "\n",
        "def build_test_set(dataset, save_dir, n_pos=16, n_neg=16):\n",
        "    pos_idx, neg_idx = [], []\n",
        "    for i in range(len(dataset)):\n",
        "        _, _, _, y = dataset[i]\n",
        "        if y == 1 and len(pos_idx) < n_pos:\n",
        "            pos_idx.append(i)\n",
        "        elif y == 0 and len(neg_idx) < n_neg:\n",
        "            neg_idx.append(i)\n",
        "        if len(pos_idx) == n_pos and len(neg_idx) == n_neg:\n",
        "            break\n",
        "    if len(pos_idx) < n_pos:\n",
        "        fill = n_pos - len(pos_idx)\n",
        "        pos_idx += neg_idx[:fill]\n",
        "        neg_idx = neg_idx[fill:]\n",
        "    if len(neg_idx) < n_neg:\n",
        "        fill = n_neg - len(neg_idx)\n",
        "        neg_idx += pos_idx[:fill]\n",
        "        pos_idx = pos_idx[fill:]\n",
        "    test_indices = pos_idx + neg_idx\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    np.save(os.path.join(save_dir, \"test_indices.npy\"), np.array(test_indices, dtype=np.int32))\n",
        "    return test_indices"
      ],
      "metadata": {
        "id": "sdKh63yhqcvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# METRICS OBJECTS (GLOBAL)"
      ],
      "metadata": {
        "id": "o04jf0-2qkF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fid_metric_global   = FrechetInceptionDistance(normalize=True).to(DEVICE)\n",
        "lpips_metric_global = lpips.LPIPS(net='alex').to(DEVICE)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_fid_lpips_masked(real_ct, gen_ct, lung_mask):\n",
        "    real = (real_ct * lung_mask + 1) / 2\n",
        "    fake = (gen_ct  * lung_mask + 1) / 2\n",
        "    real3 = real.repeat(1, 3, 1, 1).to(DEVICE)\n",
        "    fake3 = fake.repeat(1, 3, 1, 1).to(DEVICE)\n",
        "    real299 = F.interpolate(real3, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
        "    fake299 = F.interpolate(fake3, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "    fid_metric_global.reset()\n",
        "    fid_metric_global.update(real299, real=True)\n",
        "    fid_metric_global.update(fake299, real=False)\n",
        "    fid_val = float(fid_metric_global.compute().cpu())\n",
        "\n",
        "    lpips_vals = []\n",
        "    for r, g in zip(real3, fake3):\n",
        "        lpips_vals.append(float(lpips_metric_global(r.unsqueeze(0), g.unsqueeze(0)).detach().cpu()))\n",
        "    return fid_val, float(np.mean(lpips_vals))\n",
        "\n",
        "\n",
        "def inception_score_placeholder(gen_imgs):\n",
        "    return float(\"nan\"), float(\"nan\")\n"
      ],
      "metadata": {
        "id": "fMO1O2dzql8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION"
      ],
      "metadata": {
        "id": "xrgzB5iBqnjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_model(\n",
        "    unet,\n",
        "    base_sched,\n",
        "    dataset,\n",
        "    test_indices,\n",
        "    save_dir,\n",
        "    epoch,\n",
        "    steps=1000,\n",
        "    img_size=IMG,\n",
        "    device=DEVICE,\n",
        "    use_ema=False,\n",
        "    ema=None,\n",
        "    compute_heavy=False\n",
        "):\n",
        "    if use_ema and ema is not None:\n",
        "        bak = {k: v.detach().clone() for k, v in unet.state_dict().items()}\n",
        "        ema.copy_to(unet)\n",
        "\n",
        "    unet.eval()\n",
        "    batch = [dataset[i] for i in test_indices]\n",
        "    if len(batch) == 0:\n",
        "        metrics = {\n",
        "            \"psnr_mean\": 0, \"psnr_std\": 0,\n",
        "            \"ssim_mean\": 0, \"ssim_std\": 0,\n",
        "            \"mse_mean\": 0,  \"mse_std\": 0,\n",
        "            \"fid\": 0, \"lpips\": 0, \"is_mean\": 0, \"is_std\": 0\n",
        "        }\n",
        "        if use_ema and ema is not None:\n",
        "            unet.load_state_dict(bak)\n",
        "        return metrics\n",
        "\n",
        "    lung = torch.stack([b[0] for b in batch]).to(device)\n",
        "    ct   = torch.stack([b[1] for b in batch])\n",
        "    cls  = torch.stack([b[2] for b in batch]).to(device)\n",
        "\n",
        "    scheduler = copy.deepcopy(base_sched)\n",
        "    scheduler.set_timesteps(steps, device=device)\n",
        "\n",
        "    x = torch.randn((len(batch), 1, img_size, img_size), device=device)\n",
        "    for t in scheduler.timesteps:\n",
        "        inp_c = torch.cat([lung, cls, x], 1)\n",
        "        inp_u = torch.cat([lung, torch.zeros_like(cls), x], 1)\n",
        "        eps_c = unet(inp_c, t).sample\n",
        "        eps_u = unet(inp_u, t).sample\n",
        "        eps   = eps_u + CFG_SCALE * (eps_c - eps_u)\n",
        "        x     = scheduler.step(eps, t, x).prev_sample\n",
        "    gen = x.clamp(-1, 1).cpu()\n",
        "\n",
        "    psnr_list, ssim_list, mse_list = [], [], []\n",
        "    lung_cpu = lung.cpu()\n",
        "    for j, (g, y) in enumerate(zip(gen, ct)):\n",
        "        mask = lung_cpu[j]\n",
        "        g_m = g * mask\n",
        "        y_m = y * mask\n",
        "        g4, y4 = g_m.unsqueeze(0), y_m.unsqueeze(0)\n",
        "        psnr_list.append(float(psnr_fn(g4, y4, data_range=2.0)))\n",
        "        ssim_list.append(float(ssim_fn(g4, y4, data_range=2.0)))\n",
        "        mse_list.append(float(mse_fn(g4, y4)))\n",
        "\n",
        "    fid_val = lpips_val = float(\"nan\")\n",
        "    is_mean = is_std = float(\"nan\")\n",
        "    if compute_heavy:\n",
        "        fid_val, lpips_val = compute_fid_lpips_masked(ct, gen, lung_cpu)\n",
        "        is_mean, is_std    = inception_score_placeholder(gen)\n",
        "\n",
        "    metrics = {\n",
        "        \"psnr_mean\": float(np.mean(psnr_list)), \"psnr_std\": float(np.std(psnr_list)),\n",
        "        \"ssim_mean\": float(np.mean(ssim_list)), \"ssim_std\": float(np.std(ssim_list)),\n",
        "        \"mse_mean\":  float(np.mean(mse_list)),  \"mse_std\":  float(np.std(mse_list)),\n",
        "        \"fid\":   0.0 if np.isnan(fid_val)   else float(fid_val),\n",
        "        \"lpips\": 0.0 if np.isnan(lpips_val) else float(lpips_val),\n",
        "        \"is_mean\": 0.0 if np.isnan(is_mean) else float(is_mean),\n",
        "        \"is_std\":  0.0 if np.isnan(is_std)  else float(is_std),\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "    for j in range(min(4, len(gen))):\n",
        "        rows.extend([ct[j].repeat(3, 1, 1), gen[j].repeat(3, 1, 1)])\n",
        "    grid = tvu.make_grid(rows, nrow=2, normalize=True, value_range=(-1, 1))\n",
        "    eval_png = os.path.join(save_dir, f\"eval_ep{epoch:03d}.png\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    tvf.to_pil_image(grid).save(eval_png)\n",
        "\n",
        "    if use_ema and ema is not None:\n",
        "        unet.load_state_dict(bak)\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "xaJoKEP5qqiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHECKPOINT UTILS"
      ],
      "metadata": {
        "id": "woAtNRwDqwaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_checkpoint(save_dir):\n",
        "    eps = []\n",
        "    for d in os.listdir(save_dir):\n",
        "        if d.startswith(\"ep\") and d[2:].isdigit():\n",
        "            eps.append(int(d[2:]))\n",
        "    return max(eps) if eps else None\n"
      ],
      "metadata": {
        "id": "gtjLqBQsqyy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING LOOP"
      ],
      "metadata": {
        "id": "ODUGqA2Gq0yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    dataset_dir,\n",
        "    save_dir,\n",
        "    img_size=IMG,\n",
        "    batch_size=BATCH,\n",
        "    epochs=EPOCHS,\n",
        "    lr=LR,\n",
        "    t_steps=T_STEPS,\n",
        "    resume=False,\n",
        "    max_batches=None,\n",
        "    use_ema=True\n",
        "):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    print(f\"Save dir: {save_dir}\")\n",
        "\n",
        "    root = pathlib.Path(dataset_dir)\n",
        "\n",
        "    # train = train + test patients\n",
        "    train_pat = read_patient_list(root / \"train_patients.txt\")\n",
        "    test_pat  = read_patient_list(root / \"test_patients.txt\")\n",
        "    train_all = train_pat | test_pat\n",
        "\n",
        "    ds_train = LungSlice(dataset_dir, img_size=img_size, split=None, forced_patients=train_all)\n",
        "    ds_val   = LungSlice(dataset_dir, img_size=img_size, split=\"val\")\n",
        "    print(f\"Train={len(ds_train)}  Val={len(ds_val)}\")\n",
        "\n",
        "    test_idx_path = os.path.join(save_dir, \"test_indices.npy\")\n",
        "    if os.path.exists(test_idx_path):\n",
        "        test_indices = np.load(test_idx_path).astype(int).tolist()\n",
        "        print(\"Loaded test_indices.npy\")\n",
        "    else:\n",
        "        print(\"Building test set (16 pos + 16 neg) from VAL\")\n",
        "        test_indices = build_test_set(ds_val, save_dir, n_pos=16, n_neg=16)\n",
        "\n",
        "    sampler = BalancedBatchSampler(ds_train.labels, batch_size)\n",
        "    loader  = DataLoader(\n",
        "        ds_train,\n",
        "        batch_sampler=sampler,\n",
        "        pin_memory=False,\n",
        "        num_workers=2,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "\n",
        "    unet, scheduler = build_model(img_size=img_size, t_steps=t_steps)\n",
        "\n",
        "    optim = torch.optim.AdamW(unet.parameters(), lr=lr)\n",
        "    acc = Accelerator(mixed_precision=\"fp16\" if DEVICE == \"cuda\" else \"no\")\n",
        "    unet, optim, loader = acc.prepare(unet, optim, loader)\n",
        "\n",
        "    ema = EMA(unet, decay=0.999) if use_ema else None\n",
        "\n",
        "    start_epoch = 1\n",
        "    if resume:\n",
        "        last = get_last_checkpoint(save_dir)\n",
        "        if last is not None:\n",
        "            ckpt_path = os.path.join(save_dir, f\"ep{last:03d}\", \"diffusion_pytorch_model.bin\")\n",
        "            print(f\"Resuming from ep{last:03d}\")\n",
        "            unet.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
        "            if use_ema and os.path.exists(os.path.join(save_dir, f\"ep{last:03d}\", \"diffusion_pytorch_model_ema.bin\")):\n",
        "                ema_state = torch.load(\n",
        "                    os.path.join(save_dir, f\"ep{last:03d}\", \"diffusion_pytorch_model_ema.bin\"),\n",
        "                    map_location=DEVICE\n",
        "                )\n",
        "                unet.load_state_dict(ema_state, strict=False)\n",
        "                ema.register(unet)\n",
        "            start_epoch = last + 1\n",
        "        else:\n",
        "            print(\"No checkpoint found. Starting from scratch.\")\n",
        "\n",
        "    metrics_csv = os.path.join(save_dir, \"metrics.csv\")\n",
        "    if not os.path.exists(metrics_csv):\n",
        "        with open(metrics_csv, \"w\", newline='') as f:\n",
        "            csv.writer(f).writerow(\n",
        "                [\"epoch\", \"psnr_mean\", \"psnr_std\", \"ssim_mean\", \"ssim_std\",\n",
        "                 \"mse_mean\", \"mse_std\", \"fid\", \"lpips\", \"is_mean\", \"is_std\"]\n",
        "            )\n",
        "\n",
        "    print(\"Sample sanity from TRAIN:\")\n",
        "    for name, y, src in ds_train._precheck[:5]:\n",
        "        print(f\"  {name}: label={y} src={src}\")\n",
        "\n",
        "    for ep in range(start_epoch, epochs + 1):\n",
        "        torch.cuda.empty_cache()\n",
        "        unet.train()\n",
        "        tot = 0\n",
        "        n_seen = 0\n",
        "        pbar = tqdm(loader, desc=f\"ep {ep:03d}\", ncols=80)\n",
        "        for i, batch in enumerate(pbar, start=1):\n",
        "            lung, ct, cls_map, _ = batch\n",
        "            b = ct.size(0)\n",
        "            t = torch.randint(0, scheduler.config.num_train_timesteps, (b,), device=ct.device)\n",
        "            noise = torch.randn_like(ct)\n",
        "            x_t = scheduler.add_noise(ct, noise, t)\n",
        "\n",
        "            inp = torch.cat([lung, cls_map, x_t], 1)\n",
        "            eps_hat = unet(inp, t).sample\n",
        "            loss = F.mse_loss(eps_hat, noise) / GRAD_ACC\n",
        "\n",
        "            acc.backward(loss)\n",
        "            if i % GRAD_ACC == 0:\n",
        "                optim.step()\n",
        "                optim.zero_grad(set_to_none=True)\n",
        "\n",
        "            tot += float(loss.item()) * b * GRAD_ACC\n",
        "            n_seen += b\n",
        "\n",
        "            if use_ema and ema is not None:\n",
        "                ema.update(unet)\n",
        "\n",
        "            if max_batches is not None and i >= max_batches:\n",
        "                break\n",
        "\n",
        "        if acc.is_main_process:\n",
        "            print(f\"[ep {ep:03d}] loss={tot / max(1, n_seen):.4f}\")\n",
        "\n",
        "            ep_dir = os.path.join(save_dir, f\"ep{ep:03d}\")\n",
        "            os.makedirs(ep_dir, exist_ok=True)\n",
        "            torch.save(unet.state_dict(), os.path.join(ep_dir, \"diffusion_pytorch_model.bin\"))\n",
        "            if use_ema and ema is not None:\n",
        "                ema_model = copy.deepcopy(unet).to(\"cpu\")\n",
        "                ema.copy_to(ema_model)\n",
        "                torch.save(ema_model.state_dict(), os.path.join(ep_dir, \"diffusion_pytorch_model_ema.bin\"))\n",
        "                del ema_model\n",
        "\n",
        "            sample_grid(\n",
        "                unet, scheduler, ds_val,\n",
        "                os.path.join(save_dir, f\"samples_ep{ep:03d}.png\"),\n",
        "                steps=50, img_size=img_size, device=DEVICE\n",
        "            )\n",
        "\n",
        "            compute_heavy = (ep % EVAL_EVERY == 0)\n",
        "            metrics = evaluate_model(\n",
        "                unet, scheduler, ds_val, test_indices, save_dir, epoch=ep,\n",
        "                steps=1000, img_size=img_size, device=DEVICE,\n",
        "                use_ema=(use_ema and ema is not None), ema=ema,\n",
        "                compute_heavy=compute_heavy\n",
        "            )\n",
        "            print(f\"  PSNR: {metrics['psnr_mean']:.2f} ± {metrics['psnr_std']:.2f}\")\n",
        "            print(f\"  SSIM: {metrics['ssim_mean']:.3f} ± {metrics['ssim_std']:.3f}\")\n",
        "            print(f\"  MSE:  {metrics['mse_mean']:.5f} ± {metrics['mse_std']:.5f}\")\n",
        "            if compute_heavy:\n",
        "                print(f\"  FID:  {metrics['fid']:.2f}\")\n",
        "                print(f\"  LPIPS:{metrics['lpips']:.4f}\")\n",
        "                print(f\"  IS:   {metrics['is_mean']:.3f} ± {metrics['is_std']:.3f}\")\n",
        "\n",
        "            with open(metrics_csv, \"a\", newline='') as f:\n",
        "                csv.writer(f).writerow([\n",
        "                    ep,\n",
        "                    metrics['psnr_mean'], metrics['psnr_std'],\n",
        "                    metrics['ssim_mean'], metrics['ssim_std'],\n",
        "                    metrics['mse_mean'],  metrics['mse_std'],\n",
        "                    metrics['fid'], metrics['lpips'],\n",
        "                    metrics['is_mean'], metrics['is_std']\n",
        "                ])\n",
        "\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "57KJoPdLq22Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}